---
layout: default
title: 2024-07-21
parent: 2024_하계모각코
---
머신 러닝 및 최적화 에서 손실 함수를 정의하는 데 사용할 수 있습니다.

BCELoss
크로스 엔트로피 손실 함수는 정보 이론에서 크로스 엔트로피 개념을 기계 학습에 적용한 것이다. 
이 함수는 두 확률 분포 간의 차이를 측정하는 방법으로, BCE 손실 함수는 크로스 엔트로피 손실 함수를 이진 분류 문제에 적용한 형태이다.

\[ H(P, Q) = -\sum_{x} P(x) \log Q(x) \]


BCELoss는 모델의 구조 상에 마지막 Layer가 Sigmoid 혹은 Softmax로 되어 있는 경우 이를 사용한다. 즉, 모델의 출력이 각 라벨에 대한 확률값으로 구성되었을 때 사용이 가능하다. 
'''
torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')
'''

'''
import torch
import torch.nn as nn
m = nn.Sigmoid()
loss = nn.BCELoss()
input = torch.randn(3, 2, requires_grad=True)
target = torch.rand(3, 2)
output = loss(m(input), target)
output.backward()
'''





BCEWithLogitsLoss 
BCEWithLogitsLoss는 이름에서도 유추해볼 수 있듯 BCELoss를 위 과정에서 확률값(Logits)으로 변환하지 않더라도 계산되는 것을 의미한다. 
기본적인 BCE 손실 함수는 모델의 출력이 시그모이드 함수를 통과한 확률 값이어야 한다. 
그러나 이 경우수치적 불안정성(시그모이드 함수의 출력은 0과 1 사이의 값이기 때문에, 극단적인 값(예: 매우 큰 음수나 양수)에 대해 수치적으로 불안정할 수 있다.)
효율성 문제(시그모이드 함수와 BCE 손실 함수를 따로 적용하면 계산 비용이 증가할 수 있다.)가 존재할 수 있다


따라서 BCEWithLogitsLoss는 시그모이드 활성화 함수를 적용한 후 BCE 손실을 계산하는 과정을 하나의 함수로 처리한다. 
내부적으로 시그모이드 함수를 적용하고 BCE 손실을 계산하므로, 더 안정적이고 효율적이다.

\[ \text{BCEWithLogitsLoss} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\sigma(z_i)) + (1 - y_i) \log(1 - \sigma(z_i)) \right] \]

여기서:
- \( N \)은 샘플의 수
- \( y_i \)는 실제 레이블 (0 또는 1)
- \( z_i \)는 모델의 출력(로그 확률)
- \( \sigma(z) \)는 시그모이드 함수로, \(\sigma(z) = \frac{1}{1 + e^{-z}} \)





CrossEntropyLoss
이전에 다룬 BCELoss와 BCEWithLogitsLoss는 Binary Classification을 위한 손실 함수다. 
반면에 CrossEntropyLoss는 다중 분류를 위한 손실 함수다. 
예를 들어, 라벨이 5개라고 한다면 입력은 각 라벨에 대한 확률값을 표현하고, 정답 라벨은 라벨 값 혹은 라벨에 대한 확률값으로 표현할 수 있다. 
소프트맥스 활성화 함수와 크로스 엔트로피 손실을 결합한 함수로 예측 값과 실제 값 간의 차이를 직관적으로 표현할 수 있지만,
확률이 매우 작은 경우, 로그 함수로 인해 수치적 불안정성이 발생할 수 있고,클래스가 불균형한 경우 성능이 저하될 수 있습니다. 이 문제를 해결하기 위해 가중치 조정 등을 사용할 수 있다.


\[ \text{CrossEntropyLoss} = -\sum_{i=1}^{N} \sum_{c=1}^{C} y_{ic} \log(p_{ic}) \]

여기서:
- \( N \)은 샘플의 수
- \( C \)는 클래스의 수
- \( y_{ic} \)는 실제 레이블의 원-핫 인코딩 (실제 레이블이 \( c \) 클래스일 때 1, 그렇지 않으면 0)
- \( p_{ic} \)는 모델이 샘플 \( i \)에 대해 클래스 \( c \)일 확률로 예측한 값 (소프트맥스 함수의 출력)

